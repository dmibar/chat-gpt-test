# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R2d5_Jct_uq5EG4SeXts14Svy_9q54oL
"""

!pip install PyTelegramBotAPI

import telebot
import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import requests

# ==== CONFIGURATION ====
TELEGRAM_API_KEY = "7683734869:AAGSQr2aBf7W_y8GRWfliWnFfcbcVt7QIWg"

# Init bot
bot = telebot.TeleBot(TELEGRAM_API_KEY)

# ==== DATA PROCESSING FUNCTIONS ====

def generate_graphs(df: pd.DataFrame, out_dir: str = "graphs") -> None:
    os.makedirs(out_dir, exist_ok=True)
    numeric_df = df.select_dtypes(include="number")
    for col in numeric_df.columns:
        plt.figure()
        sns.histplot(numeric_df[col].dropna())
        plt.title(f"Histogram of {col}")
        plt.savefig(os.path.join(out_dir, f"{col}_hist.png"))
        plt.close()

    if len(numeric_df.columns) > 1:
        pairplot = sns.pairplot(numeric_df)
        pairplot.savefig(os.path.join(out_dir, "pairplot.png"))

def compute_stats(df: pd.DataFrame) -> pd.DataFrame:
    numeric_df = df.select_dtypes(include="number")
    results = []
    cols = list(numeric_df.columns)
    for i, col1 in enumerate(cols):
        for col2 in cols[i + 1:]:
            x = numeric_df[col1].dropna()
            y = numeric_df[col2].dropna()
            if len(x) == 0 or len(y) == 0:
                continue
            t_stat, p_val = stats.ttest_ind(x, y, equal_var=False)
            results.append({
                "col1": col1,
                "col2": col2,
                "t_stat": t_stat,
                "p_value": p_val,
            })
    return pd.DataFrame(results)

def fetch_gpt_response(prompt: str) -> str:
    url = "https://llm.api.cloud.yandex.net/foundationModels/v1/completion"
    headers = {
        "Content-Type": "application/json",
        "Authorization": "Api-Key AQVNzhlNkvh5CuDxfAXf2Yef7VEBQcaOcVOxHA8c"
    }
    payload = {
        "modelUri": "gpt://b1gr2gdlk3kmh752m813/yandexgpt/deprecated",
        "completionOptions": {
            "stream": False,
            "temperature": 0.7,
            "maxTokens": "1000"
        },
        "messages": [
            {
                "role": "system",
                "text": "–¢—ã ‚Äî –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π AutoDataScientist –ø–æ–º–æ—â–Ω–∏–∫. –î–∞–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –≤–µ—Å—ë–ª—ã–π –æ—Ç—á—ë—Ç –æ –¥–∞–Ω–Ω—ã—Ö –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ 3 –≥–∏–ø–æ—Ç–µ–∑—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏."
            },
            {
                "role": "user",
                "text": prompt
            }
        ]
    }

    response = requests.post(url, headers=headers, json=payload)
    if response.status_code == 200:
        return response.json()["result"]["alternatives"][0]["message"]["text"]
    else:
        return f"‚ö†Ô∏è Yandex GPT error: {response.status_code} {response.text}"

def generate_report(df: pd.DataFrame) -> str:
    description = f"Dataset columns: {list(df.columns)}\n"
    description += f"First rows:\n{df.head().to_csv(index=False)}"

    prompt = (
        description
        + "\n\n–°–¥–µ–ª–∞–π –≤–µ—Å—ë–ª—ã–π –æ—Ç—á—ë—Ç –æ –¥–∞—Ç–∞—Å–µ—Ç–µ –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ 3 –≥–∏–ø–æ—Ç–µ–∑—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–º–∏ –º–µ—Ç–æ–¥–∞–º–∏."
    )

    return fetch_gpt_response(prompt)

# ==== BOT HANDLERS ====

@bot.message_handler(commands=["start", "help"])
def send_welcome(message):
    bot.reply_to(message, "ü§ñ Welcome to AutoDataScientist Assistant!\n\nPlease send me a CSV file to analyze.")

@bot.message_handler(content_types=["document"])
def handle_csv(message):
    try:
        # Download file
        file_info = bot.get_file(message.document.file_id)
        downloaded_file = bot.download_file(file_info.file_path)

        filename = message.document.file_name
        local_path = os.path.join("downloads", filename)
        os.makedirs("downloads", exist_ok=True)

        with open(local_path, "wb") as f:
            f.write(downloaded_file)

        bot.reply_to(message, f"üìÇ CSV file '{filename}' received. Analyzing... Please wait.")

        # Process CSV
        df = pd.read_csv(local_path)

        # Generate graphs
        generate_graphs(df)

        # Compute stats
        stats_df = compute_stats(df)
        stats_csv_path = os.path.join("graphs", "t_test_results.csv")
        stats_df.to_csv(stats_csv_path, index=False)

        # Generate LLM report
        report_text = generate_report(df)

        # Send report
        bot.send_message(message.chat.id, "ÔøΩÌìù AI Report:\n" + report_text)

        # Send graphs
        for file in os.listdir("graphs"):
            if file.endswith(".png"):
                with open(os.path.join("graphs", file), "rb") as img:
                    bot.send_photo(message.chat.id, img)

        # Send t-test CSV
        with open(stats_csv_path, "rb") as csv_file:
            bot.send_document(message.chat.id, csv_file)

        bot.send_message(message.chat.id, "üéâ Analysis complete!")

    except Exception as e:
        bot.reply_to(message, f"‚ö†Ô∏è Error processing file: {str(e)}")

# ==== RUN BOT ====

if __name__ == "__main__":
    print("Bot is running...")
    bot.polling(none_stop=True)