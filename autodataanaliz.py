# -*- coding: utf-8 -*-
"""AutoDataAnaliz.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R2d5_Jct_uq5EG4SeXts14Svy_9q54oL
"""

!pip install PyTelegramBotAPI

import telebot
import os
import shutil
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import requests
import numpy as np
from sklearn.impute import KNNImputer
from sklearn.preprocessing import LabelEncoder
from telebot import types

# ==== CONFIGURATION ====
TELEGRAM_API_KEY = "7683734869:AAGSQr2aBf7W_y8GRWfliWnFfcbcVt7QIWg"

# Init bot
bot = telebot.TeleBot(TELEGRAM_API_KEY)

# User state management
user_states = {}
user_dfs = {}
user_outlier_cols = {}

# ==== DATA PROCESSING FUNCTIONS ====

def clean_graphs_folder():
    if os.path.exists("graphs"):
        shutil.rmtree("graphs")
    os.makedirs("graphs", exist_ok=True)

def generate_graphs(df: pd.DataFrame, out_dir: str = "graphs") -> None:
    os.makedirs(out_dir, exist_ok=True)
    numeric_df = df.select_dtypes(include="number")
    for col in numeric_df.columns:
        plt.figure()
        sns.histplot(numeric_df[col].dropna())
        plt.title(f"Histogram of {col}")
        plt.savefig(os.path.join(out_dir, f"{col}_hist.png"))
        plt.close()

    if len(numeric_df.columns) > 1:
        pairplot = sns.pairplot(numeric_df)
        pairplot.savefig(os.path.join(out_dir, "pairplot.png"))

def handle_missing_values(df: pd.DataFrame) -> pd.DataFrame:
    total_missing = df.isnull().sum().sum()
    missing_percentage = (total_missing / df.size) * 100

    if missing_percentage > 5:
        imputer = KNNImputer(n_neighbors=3)
        numeric_df = df.select_dtypes(include="number")
        df[numeric_df.columns] = imputer.fit_transform(numeric_df)
        changed_percentage = missing_percentage
    else:
        df = df.dropna()
        changed_percentage = missing_percentage

    return df, missing_percentage, changed_percentage

def detect_outliers(df: pd.DataFrame) -> list:
    os.makedirs("graphs", exist_ok=True)
    outlier_columns = []
    numeric_df = df.select_dtypes(include="number")
    for col in numeric_df.columns:
        q1 = numeric_df[col].quantile(0.25)
        q3 = numeric_df[col].quantile(0.75)
        iqr = q3 - q1
        lower_bound = q1 - 1.5 * iqr
        upper_bound = q3 + 1.5 * iqr

        outliers = numeric_df[(numeric_df[col] < lower_bound) | (numeric_df[col] > upper_bound)]

        if not outliers.empty:
            outlier_columns.append(col)

        plt.figure()
        sns.boxplot(x=numeric_df[col])
        plt.title(f"Boxplot of {col}")
        plt.savefig(os.path.join("graphs", f"{col}_boxplot.png"))
        plt.close()

        plt.figure()
        sns.histplot(numeric_df[col], kde=True)
        plt.title(f"Histplot of {col}")
        plt.savefig(os.path.join("graphs", f"{col}_histplot.png"))
        plt.close()

    return outlier_columns

def remove_outliers(df: pd.DataFrame, columns: list) -> pd.DataFrame:
    numeric_df = df.select_dtypes(include="number")
    for col in columns:
        q1 = numeric_df[col].quantile(0.25)
        q3 = numeric_df[col].quantile(0.75)
        iqr = q3 - q1
        lower_bound = q1 - 1.5 * iqr
        upper_bound = q3 + 1.5 * iqr

        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]

    return df

def generate_correlation(df: pd.DataFrame):
    os.makedirs("graphs", exist_ok=True)

    # Remove datetime columns and convert them to minutes since the first date
    datetime_cols = df.select_dtypes(include=["datetime64", "datetime64[ns]", "timedelta64"]).columns.tolist()
    for col in datetime_cols:
        df[col] = pd.to_datetime(df[col])
        df[col] = (df[col] - df[col].min()).dt.total_seconds() / 60  # Convert to minutes

    # Label encode categorical columns
    categorical_cols = df.select_dtypes(include=["object", "category"]).columns.tolist()
    for col in categorical_cols:
        le = LabelEncoder()
        df[col] = le.fit_transform(df[col].astype(str))

    # Now generate correlation matrix
    corr = df.corr()
    plt.figure(figsize=(10, 8))
    sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=".2f", vmin=-1, vmax=1)
    plt.title("Correlation Matrix")
    plt.savefig(os.path.join("graphs", "correlation_matrix.png"))
    plt.close()

def fetch_gpt_response(prompt: str) -> str:
    url = "https://llm.api.cloud.yandex.net/foundationModels/v1/completion"
    headers = {
        "Content-Type": "application/json",
        "Authorization": "Api-Key AQVNzhlNkvh5CuDxfAXf2Yef7VEBQcaOcVOxHA8c"
    }
    payload = {
        "modelUri": "gpt://b1gr2gdlk3kmh752m813/yandexgpt/deprecated",
        "completionOptions": {
            "stream": False,
            "temperature": 0.7,
            "maxTokens": "1000"
        },
        "messages": [
            {
                "role": "system",
                "text": "–¢—ã ‚Äî –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π AutoDataScientist –ø–æ–º–æ—â–Ω–∏–∫. –ü–æ–º–æ–≥–∏ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∫–æ—Ä–æ—Ç–∫—É—é –ø—Ä–æ–≤–µ—Ä—è–µ–º—É—é –≥–∏–ø–æ—Ç–µ–∑—É –ø–æ —Ç–æ–ø-3 –∫–æ—Ä—Ä–µ–ª–∏—Ä—É—é—â–∏–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º."
            },
            {
                "role": "user",
                "text": prompt
            }
        ]
    }

    response = requests.post(url, headers=headers, json=payload)
    if response.status_code == 200:
        return response.json()["result"]["alternatives"][0]["message"]["text"]
    else:
        return f"‚ö†Ô∏è Yandex GPT error: {response.status_code} {response.text}"

def proceed_to_metrics(chat_id):
    bot.send_message(chat_id, "EDA: –ú–µ—Ç—Ä–∏–∫–∏...")

    df = user_dfs[chat_id]
    numeric_df = df.select_dtypes(include="number")

    summary = ""
    for col in numeric_df.columns:
        mean = numeric_df[col].mean()
        std = numeric_df[col].std()
        min_val = numeric_df[col].min()
        max_val = numeric_df[col].max()
        summary += f"\n–ö–æ–ª–æ–Ω–∫–∞: {col}\nmean: {mean:.2f}, sd: {std:.2f}, min: {min_val}, max: {max_val}\n"

    bot.send_message(chat_id, "üìä –ò—Ç–æ–≥ –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º:" + summary)

    bot.send_message(chat_id, "–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ (–≤—ã–±—Ä–æ—Å—ã —É—á—Ç–µ–Ω—ã)...")
    generate_correlation(df)

    with open(os.path.join("graphs", "correlation_matrix.png"), "rb") as img:
        bot.send_photo(chat_id, img)

    bot.send_message(chat_id, "–•–æ—Ç–∏—Ç–µ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –≥–∏–ø–æ—Ç–µ–∑—É?")
    markup = types.InlineKeyboardMarkup()
    button_generate_hypothesis = types.InlineKeyboardButton("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –≥–∏–ø–æ—Ç–µ–∑—É", callback_data="generate_hypothesis")
    button_check_hypothesis = types.InlineKeyboardButton("–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –≥–∏–ø–æ—Ç–µ–∑—É", callback_data="check_hypothesis")
    markup.add(button_generate_hypothesis, button_check_hypothesis)
    bot.send_message(chat_id, "–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:", reply_markup=markup)

# ==== BOT HANDLERS ====

@bot.message_handler(commands=["start", "help"])
def send_welcome(message):
    markup = types.InlineKeyboardMarkup()
    button_add_info = types.InlineKeyboardButton("‚ûï –î–æ–±–∞–≤–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é", callback_data="add_info")
    markup.add(button_add_info)

    bot.send_message(message.chat.id, "ü§ñ Welcome to AutoDataScientist Assistant!\n\nPlease send me a CSV file to analyze.", reply_markup=markup)

@bot.callback_query_handler(func=lambda call: call.data == "add_info")
def handle_add_info(call):
    bot.send_message(call.message.chat.id, "‚úçÔ∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–∞–ø–∏—à–∏—Ç–µ –≤–∞—à–∏ –ø–æ–∂–µ–ª–∞–Ω–∏—è ‚Äî –º—ã –∏—Ö —É—á—Ç—ë–º –≤ –∞–Ω–∞–ª–∏–∑–µ.")
    user_states[call.message.chat.id] = {"awaiting_info": True}

@bot.message_handler(func=lambda message: user_states.get(message.chat.id, {}).get("awaiting_info"))
def handle_user_info(message):
    user_states[message.chat.id]["user_info"] = message.text
    user_states[message.chat.id]["awaiting_info"] = False

    bot.send_message(message.chat.id, "‚úÖ –í–∞—à–∏ –ø–æ–∂–µ–ª–∞–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã! –¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤—å—Ç–µ CSV –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")

@bot.message_handler(content_types=["document"])
def handle_csv(message):
    try:
        file_info = bot.get_file(message.document.file_id)
        downloaded_file = bot.download_file(file_info.file_path)

        filename = message.document.file_name
        local_path = os.path.join("downloads", filename)
        os.makedirs("downloads", exist_ok=True)

        with open(local_path, "wb") as f:
            f.write(downloaded_file)

        bot.reply_to(message, f"üìÇ {filename} received. Starting analysis...")

        df = pd.read_csv(local_path)
        user_dfs[message.chat.id] = df

        clean_graphs_folder()

        bot.send_message(message.chat.id, "EDA: –ü—Ä–æ–ø—É—Å–∫–∏...")
        df, missing_pct, changed_pct = handle_missing_values(df)
        bot.send_message(message.chat.id, f"‚úÖ –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: {missing_pct:.2f}%, –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ/—É–¥–∞–ª–µ–Ω–æ: {changed_pct:.2f}%.")

        bot.send_message(message.chat.id, "EDA: –í—ã–±—Ä–æ—Å—ã...")
        outlier_cols = detect_outliers(df)
        user_outlier_cols[message.chat.id] = outlier_cols

        if outlier_cols:
            for col in outlier_cols:
                with open(os.path.join("graphs", f"{col}_boxplot.png"), "rb") as img:
                    bot.send_photo(message.chat.id, img)
                with open(os.path.join("graphs", f"{col}_histplot.png"), "rb") as img:
                    bot.send_photo(message.chat.id, img)

            markup = types.InlineKeyboardMarkup()
            button_remove_outliers = types.InlineKeyboardButton("–£–¥–∞–ª–∏—Ç—å –≤—ã–±—Ä–æ—Å—ã", callback_data="remove_outliers")
            button_keep_outliers = types.InlineKeyboardButton("–û—Å—Ç–∞–≤–∏—Ç—å –≤—ã–±—Ä–æ—Å—ã", callback_data="keep_outliers")
            markup.add(button_remove_outliers, button_keep_outliers)

            bot.send_message(message.chat.id, f"üö® –ù–∞–π–¥–µ–Ω—ã –≤—ã–±—Ä–æ—Å—ã –≤ –∫–æ–ª–æ–Ω–∫–∞—Ö: {', '.join(outlier_cols)}. –í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:", reply_markup=markup)
        else:
            bot.send_message(message.chat.id, "‚úÖ –í—ã–±—Ä–æ—Å–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –ü–µ—Ä–µ—Ö–æ–¥–∏–º –¥–∞–ª–µ–µ...")
            proceed_to_metrics(message.chat.id)

    except Exception as e:
        bot.reply_to(message, f"‚ö†Ô∏è Error processing file: {str(e)}")

@bot.callback_query_handler(func=lambda call: call.data == "remove_outliers")
def handle_remove_outliers(call):
    df = user_dfs[call.message.chat.id]
    outlier_cols = user_outlier_cols.get(call.message.chat.id, [])
    df = remove_outliers(df, outlier_cols)
    user_dfs[call.message.chat.id] = df

    bot.send_message(call.message.chat.id, "‚úÖ –í—Å–µ –≤—ã–±—Ä–æ—Å—ã —É–¥–∞–ª–µ–Ω—ã! –ü–µ—Ä–µ—Ö–æ–¥–∏–º –¥–∞–ª–µ–µ...")
    proceed_to_metrics(call.message.chat.id)

@bot.callback_query_handler(func=lambda call: call.data == "keep_outliers")
def handle_keep_outliers(call):
    bot.send_message(call.message.chat.id, "‚úÖ –í—ã–±—Ä–æ—Å—ã –æ—Å—Ç–∞–≤–ª–µ–Ω—ã. –ü–µ—Ä–µ—Ö–æ–¥–∏–º –¥–∞–ª–µ–µ...")
    proceed_to_metrics(call.message.chat.id)

@bot.callback_query_handler(func=lambda call: call.data == "generate_hypothesis")
def handle_generate_hypothesis(call):
    df = user_dfs[call.message.chat.id]
    run_hypothesis_testing(df, call.message.chat.id)

@bot.callback_query_handler(func=lambda call: call.data == "check_hypothesis")
def handle_check_hypothesis(call):
    bot.send_message(call.message.chat.id, "‚úçÔ∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –≤–∞—à—É –≥–∏–ø–æ—Ç–µ–∑—É:")
    user_states[call.message.chat.id] = {"awaiting_hypothesis": True}

@bot.message_handler(func=lambda message: user_states.get(message.chat.id, {}).get("awaiting_hypothesis"))
def handle_user_hypothesis(message):
    hypothesis = message.text
    user_states[message.chat.id]["awaiting_hypothesis"] = False
    bot.send_message(message.chat.id, f"–í–∞—à—É –≥–∏–ø–æ—Ç–µ–∑—É: {hypothesis} –ø—Ä–æ–≤–µ—Ä—è–µ–º...")



if __name__ == "__main__":
    print("Bot is running...")
    bot.polling(none_stop=True)